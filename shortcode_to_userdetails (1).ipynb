{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-18 18:39:17.780434\n",
      "1 BexmI52lpyN tanvimehtasrivastava\n",
      "2 BexPNsZBMOF littlefoodiegirl_\n",
      "3 BuA5PccjkW1 thatsassylady\n",
      "Taken Shortcodes: 3\n",
      "Valid Shortcodes: 3\n",
      "Broken Shortcodes: 0\n",
      "Unique Shortcodes: 3\n",
      "-----------------------------------------------------------\n",
      "0\n",
      "['thatsassylady', '943', '7,127', '902', 'Samixa Tiwari', 'samixa20@gmail.com', 'NA', 'NA', 'samixa20@gmail.com', 'NA', 'Bangalore, India']\n",
      "1\n",
      "['tanvimehtasrivastava', '572', 14800, '1,990', 'PINK CRAYON', 'pinkcrayonmail@gmail.com', 'NA', 'NA', 'pinkcrayonmail@gmail.com', 'NA', 'NA']\n",
      "2\n",
      "['littlefoodiegirl_', '344', '3,424', '1,585', 'Vedshree Gupta', 'littlefoodiegirl@gmail.com', 'NA', 'NA', 'littlefoodiegirl@gmail.com', 'NA', 'NA']\n",
      "Taken Userids: 3\n",
      "Valid Userids: 3\n",
      "Broken Userids 0\n",
      "2019-02-18 18:39:27.663525\n"
     ]
    }
   ],
   "source": [
    "#working\n",
    "import requests\n",
    "import csv\n",
    "import re\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import random,time,datetime\n",
    "\n",
    "UDcount=0\n",
    "print(datetime.datetime.now())\n",
    "user_agent_list = []\n",
    "useragent=open('Useragent.txt','r')\n",
    "for ug in useragent:\n",
    "    user_agent_list.append(ug.strip())\n",
    "users=[]\n",
    "sc=[]\n",
    "f=open('instashortcode1.csv','r',encoding='utf-8')\n",
    "for line in f:\n",
    "    sc.append(line.strip())\n",
    "for i in range (0,len(sc)):\n",
    "    user_agent=user_agent_list[random.randint(0,4656)]\n",
    "    row=[]\n",
    "    if i%5==0:\n",
    "        user_agent=user_agent_list[random.randint(0,4656)]\n",
    "    try:   \n",
    "        r = requests.get(\"https://www.instagram.com/p/\"+str(sc[i]),headers={'User-Agent':user_agent })\n",
    "    except OSError:\n",
    "        print('Error at',i)\n",
    "        user_agent=user_agent_list[random.randint(0,4656)]\n",
    "        r = requests.get(\"https://www.instagram.com/p/\"+sc[i],headers={'User-Agent':user_agent })\n",
    "    if r.status_code is 200 :\n",
    "        soup = BeautifulSoup(r.text)\n",
    "    else:\n",
    "        continue\n",
    "    text2=[]\n",
    "    data = soup.find_all('link', attrs={'rel': 'canonical'})\n",
    "    text = data[0].get('href').split('/')\n",
    "    if text[3]=='p':\n",
    "        data2 = soup.find_all('meta', attrs={'property': 'og:description'})\n",
    "        text2 = data2[0].get('content').split()\n",
    "        for k in range(0,len(text2)):\n",
    "            if '(@' in text2[k]:\n",
    "                userid = text2[k].replace('(','').replace('@','').replace(')','')\n",
    "                break\n",
    "    else:\n",
    "        userid=text[3]\n",
    "    users.append(userid)\n",
    "    print(i+1,sc[i],userid)\n",
    "print('Taken Shortcodes:',len(sc))\n",
    "print('Valid Shortcodes:',len(users))\n",
    "print('Broken Shortcodes:',(len(sc)-len(users)))\n",
    "users=list(set(users))\n",
    "print('Unique Shortcodes:',len(users))\n",
    "print('-----------------------------------------------------------')\n",
    "\n",
    "#userids to userdetails\n",
    "for i in range (0,len(users)):\n",
    "    user_agent=user_agent_list[random.randint(0,4656)]\n",
    "    row=[]\n",
    "    if i%10==0:\n",
    "        user_agent=user_agent_list[random.randint(0,4656)]\n",
    "    try:\n",
    "        r = requests.get(\"https://www.instagram.com/\"+users[i],headers={'User-Agent':user_agent })\n",
    "    except OSError:\n",
    "        print('Error at',i)\n",
    "        user_agent=user_agent_list[random.randint(0,4656)]\n",
    "        r = requests.get(\"https://www.instagram.com/\"+users[i],headers={'User-Agent':user_agent })\n",
    "    if r.status_code is 200:\n",
    "         soup = BeautifulSoup(r.text)\n",
    "    else:\n",
    "        continue\n",
    "    data = soup.find_all('meta', attrs={'property': 'og:description'})\n",
    "    text=[]\n",
    "    text = data[0].get('content').split()\n",
    "    \n",
    "    #if 'k' not in text[0]:\n",
    "    #    text[0] = int(text[0].replace(',',''))\n",
    "    #    if text[0]>=1000:\n",
    "    #        followers = text[0]     #for checking the followers \n",
    "    #    else:\n",
    "    #        continue\n",
    "    #else:\n",
    "    #    followers = text[0]\n",
    "    \n",
    "    followers = text[0]\n",
    "    posts = text[4]\n",
    "    following = text[2]\n",
    "    user_id=users[i]\n",
    "    \n",
    "        \n",
    "    if 'k' in text[0]:         \n",
    "        a=text[0].strip('k')    \n",
    "        a=(float(a))*1000       \n",
    "        a=int(a)\n",
    "        followers=a               #for converting k's or m's in followers to normal integer\n",
    "    elif 'm' in text[0]:\n",
    "        a=text[0].strip('m ')\n",
    "        a=(float(a))*1000000\n",
    "        a=int(a)\n",
    "        followers=a\n",
    "    \n",
    "    hol=z=[]\n",
    "    emaildata = soup.find_all('script', attrs={'type': 'application/ld+json'})\n",
    "    hol=str(emaildata)\n",
    "    email=re.findall(r'\\\"(.+?)\\\"',hol)\n",
    "    if 'alternateName' in email:\n",
    "        text1=[]   \n",
    "        l=text.index('from')\n",
    "        if len(text)==l+2:\n",
    "            user_name=users[i]\n",
    "        else:\n",
    "            for k in range(l+1,(len(text))-1):\n",
    "                text1.append(text[k])      \n",
    "                user_name=' '.join(text1)\n",
    "    else:\n",
    "        user_name='NA'\n",
    "                               \n",
    "    if \"email\" in email:\n",
    "        email_id=email[email.index('email')+1]\n",
    "    else:\n",
    "        email_id='NA'\n",
    "    \n",
    "    if \"description\" in email:\n",
    "        description=email[email.index('description')+1].replace(\"\\n\",\"\")\n",
    "    else:\n",
    "        description='NA'\n",
    "        \n",
    "    if \"telephone\" in email:\n",
    "        telephone=email[email.index('telephone')+1]\n",
    "    else:\n",
    "        telephone='NA'\n",
    "        \n",
    "    if \"external_url\" in email:\n",
    "        external_url=email[email.index('external_url')+1]\n",
    "    else:\n",
    "        external_url='NA'\n",
    "        \n",
    "    emaildata=soup.find_all('script', attrs={'type': 'text/javascript'})\n",
    "    g=x=str(emaildata[3])\n",
    "    h=re.findall(r'[#]\\w+',g)\n",
    "    hashes=' '.join(h)\n",
    "    business=re.findall(r'\\\"(.+?)\\\"',x)\n",
    "   \n",
    "    \n",
    "    if \"city_name\\\\\" in business:\n",
    "        cityname=business[business.index('city_name\\\\')+1]\n",
    "        \n",
    "        if cityname=='\\\\':\n",
    "            cityname='NA'\n",
    "        else:\n",
    "            cityname=business[business.index('city_name\\\\')+1].replace('\\\\','')\n",
    "        \n",
    "    \n",
    "    if \"business_email\" in business:\n",
    "        b_email=business[business.index('business_email')+1]\n",
    "        if \"business\" in b_email:\n",
    "            b_email  = 'NA'\n",
    "        elif \",\" in b_email:\n",
    "            b_email = 'NA'\n",
    "    else:\n",
    "        b_email = 'NA'\n",
    "\n",
    "    if \"business_phone_number\" in business:\n",
    "        b_phoneno=business[business.index('business_phone_number')+1]\n",
    "        if \"business\" in b_phoneno:\n",
    "            b_phoneno  = 'NA'\n",
    "        elif \",\" in b_phoneno:\n",
    "            b_phoneno = 'NA'\n",
    "    else:\n",
    "        b_phoneno = 'NA'\n",
    "    print(i)\n",
    "    #row = [user_id,posts,followers,following,user_name,description,email_id,telephone,external_url,b_email,b_phoneno,hashes]#to print in csv\n",
    "    row=[user_id,posts,followers,following,user_name,email_id,telephone,external_url,b_email,b_phoneno,cityname]#hashes\n",
    "    print(row)\n",
    "    with open('userdetails1.csv', 'a',encoding='utf-8') as csvFile:\n",
    "        UDcount+=1\n",
    "        writer = csv.writer(csvFile)\n",
    "        writer.writerow(row)\n",
    "    csvFile.close()\n",
    "print('Taken Userids:',len(users))\n",
    "print('Valid Userids:',UDcount)\n",
    "print('Broken Userids',(len(users)-UDcount))\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello 1\n"
     ]
    }
   ],
   "source": [
    "b=4\n",
    "c=3\n",
    "print('hello',b-c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
